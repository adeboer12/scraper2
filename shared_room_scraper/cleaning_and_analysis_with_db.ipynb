{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import from Database and Analysis\n",
    "This notebook imports shared Craigslist listings from the database on Istanbul for initial data exploration and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import json    # library for working with JSON-formatted text strings\n",
    "import requests  # library for accessing content from web URLs\n",
    "import pprint  # library for making Python data structures readable\n",
    "import psycopg2\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "from plotly.graph_objs import *\n",
    "pp = pprint.PrettyPrinter()\n",
    "pd.options.mode.chained_assignment = None #disables warnings for editing copy of a dataframe\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) #describe() vars are not in scientific notation\n",
    "pd.set_option('max_columns', 30)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining font styles for graphics\n",
    "family = 'Arial'\n",
    "title_font = fm.FontProperties(family=family, style='normal', size=18, weight='normal', stretch='normal')\n",
    "label_font = fm.FontProperties(family=family, style='normal', size=16, weight='normal', stretch='normal')\n",
    "ticks_font = fm.FontProperties(family=family, style='normal', size=14, weight='normal', stretch='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating function for defining colors for graphics\n",
    "def get_colors(cmap, n, start=0., stop=1., alpha=1., reverse=False):\n",
    "    '''return n-length list of rgba colors from the passed colormap name and alpha,\n",
    "       limit extent by start/stop values and reverse list order if flag is true'''\n",
    "    colors = [cm.get_cmap(cmap)(x) for x in np.linspace(start, stop, n)]\n",
    "    colors = [(r, g, b, alpha) for r, g, b, _ in colors]\n",
    "    return list(reversed(colors)) if reverse else colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in credentials from private settings file\n",
    "with open('settings.json') as settings_file:    \n",
    "    settings = json.load(settings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try to connect to database on local machine\n",
    "dbname = settings['dbname']\n",
    "user = settings['user']\n",
    "host = settings['host']\n",
    "password = settings['password']\n",
    "\n",
    "conn_str = \"dbname = {0} user = {1} host = {2} password = {3}\".format(dbname, user, host, password)\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(conn_str)\n",
    "except:\n",
    "    print (\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example dataframe with all the listings (as of 04/24, about 23k listings)\n",
    "df = pd.read_sql_query(\"select * from shared_listings;\",con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example SQL pulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example syntax for pulling just those from newyork domain\n",
    "df_nyc = pd.read_sql_query(\"select * from shared_listings where region = 'newyork';\",con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example syntax for pulling just those on a specific date (April 22)\n",
    "df_april25 = pd.read_sql_query(\"select * from shared_listings where dt >= '2017-04-25' AND dt < '2017-04-23';\",con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example syntax for pulling just those on a specific date (April 22)\n",
    "df_april25 = pd.read_sql_query(\"select * from shared_listings where dt >= '2017-04-25';\",con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_april24 = pd.read_sql_query(\"select * from shared_listings where dt >= '2017-04-24'AND dt < '2017-04-25';\",con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_april23 = pd.read_sql_query(\"select * from shared_listings where dt >= '2017-04-23'AND dt < '2017-04-24';\",con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#close database connection (no longer needed)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.lat == 99, 'lat'] = 0\n",
    "df.loc[df.lng == 99, 'lng'] = 0\n",
    "df.loc[df.sqft == 0, 'sqft'] = np.nan\n",
    "\n",
    "#For any duplicate post, we want to keep the version with the most information. Therefore, assign a score to each post and \n",
    "#give one point for square footage, lat, long and price\n",
    "\n",
    "df['price_exists'] = df['rent']>0\n",
    "df['sqft_exists'] = df['sqft']>0\n",
    "df['lat_exists'] = df['lat']>0\n",
    "df['lng_exists'] = df['lng']<0\n",
    "df['score'] = df[['price_exists','sqft_exists','lat_exists','lng_exists']].astype(bool).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort rows by score\n",
    "df = df.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dedupe1 = pd.DataFrame(df.drop_duplicates(subset='pid', inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dedupe1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe2 = pd.DataFrame(dedupe1.drop_duplicates(subset='body_text', inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick bar chart to see impact of deduplication on sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [len(df),len(dedupe1), len(dedupe2)]\n",
    "labels = ['original', 'dedupe_pid', 'dedupe_body']\n",
    "x = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6) )\n",
    "plt.suptitle('Deduplication Sample Size')\n",
    "plt.xlabel('Deduplication Phase')\n",
    "plt.ylabel('Number of Listings')\n",
    "plt.xticks(x, labels)\n",
    "ax = plt.bar(x, y, alpha=.4, color='cyan', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for plotting same histo w/Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For initializing offline mode. Not working though...\n",
    "#py.offline.init_notebook_mode() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [Bar(x=['original','dedupe_pid','dedupe_body'], y=[len(df),len(dedupe1), len(dedupe2)])]\n",
    "py.offline.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out listings that don't include rent price\n",
    "unique_wprice = dedupe2[dedupe2['rent'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_wprice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, define the values by which we will filter the 3 columns. This will vary depending on the sample we're looking at. \n",
    "upper_percentile = 0.997\n",
    "lower_percentile = 0.08\n",
    "\n",
    "# how many rows would be within the upper and lower percentiles?\n",
    "upper = int(len(unique_wprice) * upper_percentile)\n",
    "lower = int(len(unique_wprice) * lower_percentile)\n",
    "\n",
    "# get the rent values at the upper and lower percentiles\n",
    "rent_sorted = unique_wprice['rent'].sort_values(ascending=True, inplace=False)\n",
    "upper_rent = rent_sorted.iloc[upper]\n",
    "lower_rent = rent_sorted.iloc[lower]\n",
    "\n",
    "# get the sqft values at the upper and lower percentiles\n",
    "sqft_sorted = unique_wprice['sqft'].sort_values(ascending=True, inplace=False)\n",
    "upper_sqft = sqft_sorted.iloc[upper]\n",
    "lower_sqft = sqft_sorted.iloc[lower]\n",
    "\n",
    "print('valid rent range:', [lower_rent, upper_rent])\n",
    "print('valid sqft range:', [lower_sqft, upper_sqft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out rows with unreasonable rent prices \n",
    "rent_mask = (unique_wprice['rent'] > lower_rent) & (unique_wprice['rent'] < upper_rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_listings = pd.DataFrame(unique_wprice[rent_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_listings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe that only includes shared listings that are private rooms\n",
    "filtered_private_only = filtered_listings[filtered_listings['private_room']==True]\n",
    "\n",
    "filtered_private_only.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Filtered Database Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ratios = pd.DataFrame()\n",
    "\n",
    "#Number of total shared listings for reach region before deduplication or filtering\n",
    "listings_ratios['all_shared_listings'] = df['region'].value_counts()\n",
    "\n",
    "listings_ratios['deduplicated_pid'] = dedupe1['region'].value_counts()\n",
    "\n",
    "listings_ratios['deduplicated_text'] = dedupe2['region'].value_counts()\n",
    "\n",
    "listings_ratios['duplicate_listings'] = listings_ratios['all_shared_listings'] - listings_ratios['deduplicated_text'] \n",
    "\n",
    "listings_ratios['duplicate_ratio'] = listings_ratios['duplicate_listings']/listings_ratios['all_shared_listings']\n",
    "\n",
    "listings_ratios['unique_ratio'] = listings_ratios['deduplicated_text']/listings_ratios['all_shared_listings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ratios of unique and duplicate listings, by region. This is before dropping observations without lat-lngs!\n",
    "\n",
    "countdata = listings_ratios.sort_values(by='all_shared_listings', ascending=False)[['deduplicated_text','duplicate_listings']].head(20)\n",
    "countdata.columns = ['Unique Listings', 'Duplicate Listings']\n",
    "ax = countdata.plot(kind='bar',\n",
    "                    stacked=True,\n",
    "                    figsize=[10, 6], \n",
    "                    width=0.6, \n",
    "                    alpha=0.5, \n",
    "                    color=['b','m'],\n",
    "                    edgecolor='k',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(countdata.index, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Unique and Duplicate Shared Rental Listings, by Region', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Total number of listings', fontproperties=label_font)        \n",
    "\n",
    "#save_fig(plt.gcf(), 'count_unique_duplicate_listings.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Spatial Join for Census Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "pylab.rcParams['figure.figsize'] = 10, 8\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california = gpd.read_file('ca_census_shapefile//cb_2015_06_tract_500k.shp')\n",
    "print(type(california))\n",
    "print(california.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use California CRS\n",
    "# California.crs = {'init' :'epsg:2227'}\n",
    "#http://spatialreference.org/ref/epsg/2227/\n",
    "california_crs = {'init': 'epsg:2227'}\n",
    "california = california.to_crs(california_crs)\n",
    "print(california.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfbay = filtered_private_only[filtered_private_only['region']=='sfbay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sfbay = sfbay[sfbay.lat != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "los_angeles = filtered_private_only[filtered_private_only['region']=='losangeles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_angeles = los_angeles[los_angeles.lat != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LA GeoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometryMapping_la = [Point(xy) for xy in zip(los_angeles.lng, los_angeles.lat)]\n",
    "geo_la = GeoDataFrame(los_angeles, crs={'init' :'epsg:4326'}, geometry=geometryMapping_la)\n",
    "geo_la=geo_la.to_crs(california_crs)\n",
    "print(type(geo_la))\n",
    "print(geo_la.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SF GeoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometryMapping = [Point(xy) for xy in zip(sfbay.lng, sfbay.lat)]\n",
    "geo_sf = GeoDataFrame(sfbay, crs={'init' :'epsg:4326'}, geometry=geometryMapping)\n",
    "geo_sf=geo_sf.to_crs(california_crs)\n",
    "print(type(geo_sf))\n",
    "print(geo_sf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_joined = gpd.sjoin(geo_la, california, how='inner', op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_joined = gpd.sjoin(geo_sf, california, how=\"inner\", op='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary fields that came from Census shapefile\n",
    "la_joined.drop(['ALAND','LSAD','NAME','AWATER','AFFGEOID','STATEFP','COUNTYFP'], axis=1, inplace=True)\n",
    "sf_joined.drop(['ALAND','LSAD','NAME','AWATER','AFFGEOID','STATEFP','COUNTYFP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = california.plot(color='gray', linewidth=.1)\n",
    "sf_joined.plot(color='red', ax=base)\n",
    "la_joined.plot(color='b', ax=base)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Vacant to Shared Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacant = pd.read_csv('vacant_april_listings.csv',dtype={'fips_block':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a GEOID field that's comparable to shared listings\n",
    "vacant['GEOID'] = vacant['fips_block'].str[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning studios into 1BRs for calculating rent per bedroom\n",
    "vacant['beds2'] = vacant['beds']\n",
    "vacant.loc[vacant.beds2 == 0, 'beds2'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacant['rent_per_br'] = vacant['rent']/vacant['beds2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, define the values by which we will filter the 3 columns. This will vary depending on the sample we're looking at. \n",
    "upper_percentile = 0.99\n",
    "lower_percentile = 0.01\n",
    "\n",
    "# how many rows would be within the upper and lower percentiles?\n",
    "upper = int(len(vacant) * upper_percentile)\n",
    "lower = int(len(vacant) * lower_percentile)\n",
    "\n",
    "# get the rent/sqft values at the upper and lower percentiles\n",
    "rent_sqft_sorted = vacant['rent_sqft'].sort_values(ascending=True, inplace=False)\n",
    "upper_rent_sqft = rent_sqft_sorted.iloc[upper]\n",
    "lower_rent_sqft = rent_sqft_sorted.iloc[lower]\n",
    "\n",
    "# get the rent values at the upper and lower percentiles\n",
    "rent_sorted = vacant['rent'].sort_values(ascending=True, inplace=False)\n",
    "upper_rent = rent_sorted.iloc[upper]\n",
    "lower_rent = rent_sorted.iloc[lower]\n",
    "\n",
    "# get the sqft values at the upper and lower percentiles\n",
    "sqft_sorted = vacant['sqft'].sort_values(ascending=True, inplace=False)\n",
    "upper_sqft = sqft_sorted.iloc[upper]\n",
    "lower_sqft = sqft_sorted.iloc[lower]\n",
    "\n",
    "print('valid rent_sqft range:', [lower_rent_sqft, upper_rent_sqft])\n",
    "print('valid rent range:', [lower_rent, upper_rent])\n",
    "print('valid sqft range:', [lower_sqft, upper_sqft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out rows with unreasonable rent prices \n",
    "rent_mask = (vacant['rent'] > lower_rent) & (vacant['rent'] < upper_rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_vacant = pd.DataFrame(vacant[rent_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot of median prices for total sample\n",
    "print('median rent for all vacant listings:', filtered_vacant['rent'].median())\n",
    "print('median rent for all vacant Studio Units:',(filtered_vacant[filtered_vacant['beds']==0])['rent_per_br'].median())\n",
    "print('median rent for all vacant 1BR Units:',(filtered_vacant[filtered_vacant['beds']==1])['rent_per_br'].median())\n",
    "\n",
    "print('median rent per bedroom for all vacant listings:', filtered_vacant['rent_per_br'].median())\n",
    "print('median rent per bedroom for all multi-bedroom vacant listings:', (filtered_vacant[filtered_vacant['beds'] > 1])['rent_per_br'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacant_sfbay = vacant[vacant['region']=='sfbay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacant_sfbay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: If we apply a filter for individual regions, we'd probably want to adjust the parameters to account for the smaller \n",
    "# sample size and different market; for example, $5000 is not a super atypical price in the Bay Area, shouldn't be filtered out \n",
    "print('median rent for all SF vacant listings:', vacant_sfbay['rent'].median())\n",
    "print('median rent for all SF vacant Studio Units:',(vacant_sfbay[vacant_sfbay['beds']==0])['rent_per_br'].median())\n",
    "print('median rent for all SF vacant 1BR Units:',(vacant_sfbay[vacant_sfbay['beds']==1])['rent_per_br'].median())\n",
    "\n",
    "print('median rent per bedroom for all SF vacant listings:', vacant_sfbay['rent_per_br'].median())\n",
    "print('median rent per bedroom for all SF multi-bedroom vacant listings:', (vacant_sfbay[vacant_sfbay['beds'] > 1])['rent_per_br'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('median rent for room in SF shared listing:', sf_joined['rent'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vacant_la = vacant[vacant['region']=='losangeles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vacant2 = vacant[(vacant['GEOID'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and aggragating by GEOID for vacant SF listings\n",
    "sf_vacant_grouped = vacant_sfbay.groupby(by='GEOID')\n",
    "sf_vacant_grouped = sf_vacant_grouped.agg({'rent_per_br':['mean','median','count']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, need to turn newly created multi-index dataframe into a single index dataframe \n",
    "sf_vacant_grouped.columns = sf_vacant_grouped.columns.get_level_values(1)\n",
    "\n",
    "sf_vacant_grouped.columns = ['GEOID','tract_mean','tract_median','tract_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_vacant_grouped.sort_values(by='tract_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_shared_grouped = sf_joined.groupby(by='GEOID')\n",
    "sf_shared_grouped = sf_shared_grouped.agg({'rent':['mean','median','count']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, need to turn newly created multi-index \n",
    "sf_shared_grouped.columns = sf_shared_grouped.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf_shared_grouped.columns = ['GEOID','tract_mean','tract_median','tract_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_shared_grouped.sort_values(by='tract_count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging shared and vacant listings on GEOID\n",
    "sf_compare=pd.merge(sf_shared_grouped,sf_vacant_grouped,how='outer',on='GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_compare.sort_values(by='tract_count_x', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting NaNs to 0s\n",
    "#sf_compare = sf_compare.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating column that calculates difference between tract medians for vacant and shared listings\n",
    "sf_compare['difference'] = sf_compare['tract_median_y'] - sf_compare['tract_median_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by tracts with most shared listings\n",
    "sf_compare.sort_values(by='tract_count_x', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary to keep lead '0' in GEOID column when exported to .csv. Only for ArcMap\n",
    "# sf_compare.GEOID = sf_compare.GEOID.apply('=\"{}\"'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf_compare.to_csv('sf_compare.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings_ratios['all_vacant_listings'] = vacant['region'].value_counts()\n",
    "listings_ratios['shared_to_vacant_ratio'] = listings_ratios['deduplicated_pid']/listings_ratios['all_vacant_listings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ratios of shared and vacant listings, by region\n",
    "countdata = listings_ratios.sort_values(by='all_shared_listings', ascending=False)[['deduplicated_pid','all_vacant_listings']].head(20)\n",
    "countdata.columns = ['Shared Listings', 'Vacant Listings']\n",
    "ax = countdata.plot(kind='bar',\n",
    "                    stacked=True,\n",
    "                    figsize=[9, 6], \n",
    "                    width=0.6, \n",
    "                    alpha=0.5, \n",
    "                    color=['b','m'],\n",
    "                    edgecolor='k',\n",
    "                    grid=False)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks(range(0, len(countdata)))\n",
    "ax.set_xticklabels(countdata.index, rotation=40, rotation_mode='anchor', ha='right', fontproperties=ticks_font)\n",
    "for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(ticks_font)\n",
    "ax.set_title('Unique and Duplicate Shared Rental Listings, by region', fontproperties=title_font)\n",
    "ax.set_xlabel('', fontproperties=label_font)\n",
    "ax.set_ylabel('Total number of listings', fontproperties=label_font)        \n",
    "\n",
    "#save_fig(plt.gcf(), 'count_unique_duplicate_listings.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
